from playwright.sync_api import sync_playwright
import os
from dotenv import load_dotenv
import pandas as pd


def search_location(page, target):
    nearby_search_box = page.locator("input#searchboxinput")
    nearby_search_box.fill(target)
    page.locator("button#searchbox-searchbutton").click()
    page.wait_for_timeout(5000)

    print("å®Œæˆæœå°‹ï¼Œå¯ä»¥æŸ¥çœ‹çµæœã€‚")

    page.wait_for_selector("div.Nv2PK", timeout=10000)

    # æ“·å–æ•´é  HTML
    html = page.content()

    # ä½¿ç”¨ BeautifulSoup è§£æçµæœ
    from bs4 import BeautifulSoup
    soup = BeautifulSoup(html, "html.parser")

    # æ“·å–è¨ºæ‰€/é†«é™¢è³‡è¨Š
    results = []
    entries = soup.select("div.Nv2PK")
    for entry in entries:
        name = entry.select_one(".qBF1Pd.fontHeadlineSmall")
        address = None

    # ğŸ” æŠ“æ‰€æœ‰ W4Efsd çš„å€å¡Š
        info_blocks = entry.select(".W4Efsd")
        # print(info_blocks)
        for block in info_blocks:
            if "è™Ÿ" in block.get_text():  # æ‰¾çœ‹èµ·ä¾†åƒåœ°å€çš„
                spans = block.find_all("span")
                for span in spans:
                    if "è™Ÿ" in span.get_text():  # å°‹æ‰¾çœŸæ­£åŒ…å«åœ°å€çš„ span
                        address = span.get_text(strip=True)
                        break
            if address:
                break

        if name and address:
            results.append({
                "name": name.text.strip(),
                "address": address
            })
    for r in results:
        print(f"{r['name']} - {r['address']}")
    return results



df = pd.read_excel('Patient_data.xlsx', sheet_name='Sheet1')
patient_location = df['åœ°å€']

with sync_playwright() as p:
    browser = p.chromium.launch(headless=False)
    page = browser.new_page()

    page.goto("https://www.google.com/maps/")
    page.wait_for_timeout(3000)

    all_results = []

    for input_address in patient_location:
        print(f"è™•ç†åœ°å€ï¼š{input_address}")
        search_box = page.locator("input#searchboxinput")
        search_box.fill(input_address)
        page.locator("button#searchbox-searchbutton").click()
        page.wait_for_timeout(5000)

        clincs = search_location(page, "è¨ºæ‰€")
        hospitals = search_location(page, "é†«é™¢")
        pharmacies = search_location(page, "è—¥å±€")

        all_results.append({
            "åœ°å€": input_address,
            "è¨ºæ‰€": clincs,
            "é†«é™¢": hospitals
        })

    input("æŒ‰ Enter é—œé–‰ç€è¦½å™¨...")
    browser.close()
# print(all_results)``

# for input_address in patient_location:

#     with sync_playwright() as p:
#         browser = p.chromium.launch(headless=False)  # é¡¯ç¤ºç€è¦½å™¨
#         page = browser.new_page()

#         print("å•Ÿå‹•ç€è¦½å™¨ï¼Œé€²å…¥Google Map")

#         # é€²å…¥ Facebook ç™»å…¥é é¢
#         page.goto("https://www.google.com/maps/")
#         page.wait_for_timeout(3000)

#         # è¼¸å…¥åœ°å€ï¼ˆä¾‹å¦‚ "Taipei 101"ï¼‰
#         # input_address = "å°åŒ—å¸‚å¤§å®‰å€"
#         print(f"è¼¸å…¥åœ°å€ï¼š{input_address}")
#         search_box = page.locator("input#searchboxinput")
#         search_box.fill(input_address)
#         page.locator("button#searchbox-searchbutton").click()
#         page.wait_for_timeout(5000)

#         # æœå°‹é™„è¿‘è¨ºæ‰€æˆ–é†«é™¢
#         print("æœå°‹é™„è¿‘è¨ºæ‰€æˆ–é†«é™¢")
#         # é»æ“Šå·¦ä¸Šè§’çš„ã€Œæœå°‹é™„è¿‘ã€
#         page.keyboard.press("Tab")  # å¯èƒ½éœ€è¦æ ¹æ“šç‹€æ³å¤šæ¬¡ Tabï¼Œé€™è£¡å‡è¨­å·² focus åˆ°æ­£ç¢ºä½ç½®
#         page.keyboard.press("Tab")
#         page.keyboard.press("Enter")
#         page.wait_for_timeout(2000)

#         # è¼¸å…¥ã€Œè¨ºæ‰€æˆ–é†«é™¢ã€
#         def search_location(target):
#             nearby_search_box = page.locator("input#searchboxinput")
#             nearby_search_box.fill(target)
#             page.locator("button#searchbox-searchbutton").click()
#             page.wait_for_timeout(5000)

#             print("å®Œæˆæœå°‹ï¼Œå¯ä»¥æŸ¥çœ‹çµæœã€‚")

#             page.wait_for_selector("div.Nv2PK", timeout=10000)

#             # æ“·å–æ•´é  HTML
#             html = page.content()

#             # ä½¿ç”¨ BeautifulSoup è§£æçµæœ
#             from bs4 import BeautifulSoup
#             soup = BeautifulSoup(html, "html.parser")

#             # æ“·å–è¨ºæ‰€/é†«é™¢è³‡è¨Š
#             results = []
#             entries = soup.select("div.Nv2PK")
#             for entry in entries:
#                 name = entry.select_one(".qBF1Pd.fontHeadlineSmall")
#                 # address = entry.select_one(".W4Efsd span:nth-of-type(2)")
#                 # address_div = entry.select_one(".W4Efsd")
            
#                 # if address_div:
#                 #     # é¸æ“‡åœ°å€æ‰€åœ¨çš„ span æ¨™ç±¤ä¸¦æå–
#                 #     address = None
#                 #     address_spans = address_div.find_all("span")
#                 #     print(address_spans)
#                 address = None

#             # ğŸ” æŠ“æ‰€æœ‰ W4Efsd çš„å€å¡Š
#                 info_blocks = entry.select(".W4Efsd")
#                 # print(info_blocks)
#                 for block in info_blocks:
#                     if "è™Ÿ" in block.get_text():  # æ‰¾çœ‹èµ·ä¾†åƒåœ°å€çš„
#                         spans = block.find_all("span")
#                         for span in spans:
#                             if "è™Ÿ" in span.get_text():  # å°‹æ‰¾çœŸæ­£åŒ…å«åœ°å€çš„ span
#                                 address = span.get_text(strip=True)
#                                 break
#                     if address:
#                         break

#                 if name and address:
#                     results.append({
#                         "name": name.text.strip(),
#                         "address": address
#                     })
#             for r in results:
#                 print(f"{r['name']} - {r['address']}")
#             return results
        
#         clincs = search_location("è¨ºæ‰€")
#         hospitals = search_location("é†«é™¢")
#         print(clincs)
#         # å¯åŠ ï¼šä¿ç•™ç•«é¢ç›´åˆ°æ‰‹å‹•é—œé–‰
#         input("æŒ‰ä¸‹ Enter é—œé–‰ç€è¦½å™¨...")
#         browser.close()